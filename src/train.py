import torch
import torch.optim as optim
import torch.nn as nn
from torch.utils.data import DataLoader, random_split, Subset
import os

# --- å¯¼å…¥æˆ‘ä»¬æ‹†åˆ†å¥½çš„æ¨¡å— ---
from .config import Config  # å¯¼å…¥é…ç½®
from .utils import compute_masked_loss, calculate_f1  # å¯¼å…¥å·¥å…·å‡½æ•°
from .dataset import MultiFileDataset, collate_pad,MultiFileDatasetUpgrade  # å‡è®¾ä½ å·²ç»æœ‰äº†è¿™ä¸ªæ–‡ä»¶
# from .model import SpotRNAWithLSTM  # å‡è®¾ä½ å·²ç»æœ‰äº†è¿™ä¸ªæ–‡ä»¶
from .model import SpotRNA_LSTM_Refined
from .cluster_split import parse_cdhit_clstr, create_cluster_splits, save_split_config

def train(clstr_path=None, split_seed=42, train_frac=0.8, val_frac=0.1, split_out=None):
    print(f"ä½¿ç”¨è®¾å¤‡: {Config.DEVICE}")

    # --- 1. å‡†å¤‡æ•°æ® ---
    # ç›´æ¥ä½¿ç”¨ Config ä¸­çš„å‚æ•°
    full_ds = MultiFileDatasetUpgrade(Config.DATA_DIR, max_len=Config.MAX_LEN)

    if len(full_ds) == 0:
        print("é”™è¯¯ï¼šæ²¡æœ‰æ•°æ®ï¼Œè¯·æ£€æŸ¥è·¯å¾„ã€‚")
        return

    # åˆ’åˆ†éªŒè¯é›† - ä½¿ç”¨èšç±»åˆ†å‰²æˆ–éšæœºåˆ†å‰²
    if clstr_path and os.path.exists(clstr_path):
        print(f"\nğŸ”¬ ä½¿ç”¨èšç±»æ–‡ä»¶è¿›è¡Œæ— æ³„æ¼åˆ†å‰²: {clstr_path}")
        
        # Parse cluster file
        name_to_cluster = parse_cdhit_clstr(clstr_path)
        
        # Create cluster-based splits
        train_indices, val_indices, test_indices = create_cluster_splits(
            full_ds, 
            name_to_cluster,
            train_frac=train_frac,
            val_frac=val_frac,
            seed=split_seed
        )
        
        # Create Subset datasets
        train_ds = Subset(full_ds, train_indices)
        val_ds = Subset(full_ds, val_indices)
        
        # Save split configuration if requested
        if split_out:
            metadata = {
                "clstr_path": clstr_path,
                "split_seed": split_seed,
                "train_frac": train_frac,
                "val_frac": val_frac,
                "n_clusters": len(set(name_to_cluster.values())),
                "max_len": Config.MAX_LEN
            }
            save_split_config(split_out, train_indices, val_indices, test_indices, metadata)
    else:
        print("\nğŸ² ä½¿ç”¨éšæœºåˆ†å‰² (æœªæŒ‡å®šèšç±»æ–‡ä»¶)")
        train_len = int(0.9 * len(full_ds))
        val_len = len(full_ds) - train_len
        # ä½¿ç”¨ random_split
        train_ds, val_ds = random_split(full_ds, [train_len, val_len])

    train_loader = DataLoader(train_ds, batch_size=Config.BATCH_SIZE, shuffle=True, collate_fn=collate_pad)
    val_loader = DataLoader(val_ds, batch_size=Config.BATCH_SIZE, shuffle=False, collate_fn=collate_pad)

    # --- 2. åˆå§‹åŒ–æ¨¡å‹ --- æ­¤å¤„ä½¿ç”¨ResNet+LSTM
    # model = SpotRNAWithLSTM(
    #     num_resnet_layers=Config.RESNET_LAYERS,
    #     hidden_dim=Config.HIDDEN_DIM,
    #     lstm_hidden=Config.LSTM_HIDDEN
    # ).to(Config.DEVICE)

    #æ­¤å¤„ä½¿ç”¨ResNet+Transformer
    model = SpotRNA_LSTM_Refined(
        Config
    ).to(Config.DEVICE)

    # ====== ã€æ–°å¢ã€‘åŠ è½½é¢„è®­ç»ƒæƒé‡ ======
    if Config.PRETRAINED_PATH and os.path.exists(Config.PRETRAINED_PATH):
        print(f"æ­£åœ¨åŠ è½½é¢„è®­ç»ƒæƒé‡: {Config.PRETRAINED_PATH}")
        try:
            # åŠ è½½æƒé‡
            state_dict = torch.load(Config.PRETRAINED_PATH, map_location=Config.DEVICE)
            model.load_state_dict(state_dict)
            print(">>> æƒé‡åŠ è½½æˆåŠŸï¼å°†åœ¨ç°æœ‰åŸºç¡€ä¸Šç»§ç»­è®­ç»ƒã€‚")
        except Exception as e:
            print(f"!!! æƒé‡åŠ è½½å¤±è´¥: {e}")
            return # æˆ–è€…é€‰æ‹©ç»§ç»­ä»å¤´è®­ç»ƒ
    else:
        print("æœªæŒ‡å®šé¢„è®­ç»ƒæƒé‡ï¼Œå°†ä»å¤´å¼€å§‹è®­ç»ƒã€‚")
    # ====================================

    optimizer = optim.Adam(model.parameters(), lr=Config.LR,weight_decay=Config.WEIGHT_DECAY)

    # --- 3. Loss å®šä¹‰ ---
    pos_weight_tensor = torch.tensor([Config.POS_WEIGHT]).to(Config.DEVICE)
    # criterion_raw = nn.BCEWithLogitsLoss(pos_weight=pos_weight_tensor, reduction='none')

    # --- 4. å¼€å§‹è®­ç»ƒå¾ªç¯ ---
    print(f"\nå¼€å§‹è®­ç»ƒ (Epochs={Config.EPOCHS}, Accum={Config.ACCUM_STEPS})...")

    for epoch in range(Config.EPOCHS):
        model.train()
        optimizer.zero_grad()  # æ¸…ç†ä¸Šä¸€è½®æ®‹ç•™
        total_loss = 0

        for batch_idx, (seqs, labels, masks) in enumerate(train_loader):
            seqs = seqs.to(Config.DEVICE)
            labels = labels.to(Config.DEVICE)
            masks = masks.to(Config.DEVICE)

            # === ä¿®æ”¹ 1: ä¼ å…¥ mask ===
            logits = model(seqs, mask=masks)

            # === ä¿®æ”¹ 2: è°ƒç”¨ utils è®¡ç®— loss (å¸¦ pos_weight) ===
            # ç›´æ¥åœ¨è¿™é‡Œä¼ å…¥ pos_weightï¼Œä¸ä¾èµ–å¤–éƒ¨ criterion
            loss = compute_masked_loss(logits, labels, masks, pos_weight=Config.POS_WEIGHT)

            loss = loss / Config.ACCUM_STEPS
            loss.backward()

            # è®°å½•è¿˜åŸåçš„çœŸå® Loss
            current_real_loss = loss.item() * Config.ACCUM_STEPS
            total_loss += current_real_loss

            # è¾¾åˆ°ç´¯ç§¯æ­¥æ•°è¿›è¡Œæ›´æ–°
            if (batch_idx + 1) % Config.ACCUM_STEPS == 0:
                # å¯é€‰ï¼šæ¢¯åº¦è£å‰ª
                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)

                optimizer.step()
                optimizer.zero_grad()

            if batch_idx % 50 == 0:
                print(f"Step [{batch_idx}] Loss: {current_real_loss:.4f}")

        avg_loss = total_loss / len(train_loader)
        print(f"=== Epoch {epoch + 1} ç»“æŸ, å¹³å‡ Loss: {avg_loss:.4f} ===")

        # --- 5. éªŒè¯ (Validation) ---
        model.eval()
        val_loss = 0
        val_f1 = 0

        with torch.no_grad():
            for seqs, labels, masks in val_loader:
                seqs = seqs.to(Config.DEVICE)
                labels = labels.to(Config.DEVICE)
                masks = masks.to(Config.DEVICE)

                # [ä¿®æ­£1] éªŒè¯æ—¶ä¹Ÿè¦ä¼ å…¥ maskï¼Œé¿å… Padding å¹²æ‰°
                logits = model(seqs, mask=masks)

                # [ä¿®æ­£2] è¿™é‡Œä¸èƒ½ä¼  criterion_raw äº†ï¼Œè¦ä¼  pos_weight
                loss = compute_masked_loss(logits, labels, masks, pos_weight=Config.POS_WEIGHT)

                val_loss += loss.item()

                # ä½¿ç”¨å·¥å…·å‡½æ•°è®¡ç®— F1
                f1 = calculate_f1(logits, labels, masks)
                val_f1 += f1

        print(f"=== éªŒè¯é›† Loss: {val_loss / len(val_loader):.4f} | F1: {val_f1 / len(val_loader):.4f} ===\n")

        # ä¿å­˜æ¨¡å‹ (å»ºè®®æ–‡ä»¶åæ”¹å¾—æ›´æœ‰æ„ä¹‰ä¸€ç‚¹)
        save_path = os.path.join(Config.MODEL_SAVE_DIR, f"model_transformer_epoch_{epoch + 1}.pth")
        torch.save(model.state_dict(), save_path)


if __name__ == "__main__":
    train()